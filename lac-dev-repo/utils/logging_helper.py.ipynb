{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8ccf97cc-b1db-40fc-9825-363ee79f7d39",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "# Import libraries\n",
    "from pyspark.sql.types import (\n",
    "    StructType, StructField, StringType, IntegerType, DateType,TimestampType, LongType\n",
    ")\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the schema for your log entries\n",
    "log_schema = StructType([\n",
    "    StructField(\"LogDate\", DateType(), True),\n",
    "    StructField(\"ExecutionDate\", TimestampType(), True),\n",
    "    StructField(\"Stage\", StringType(), True),\n",
    "    StructField(\"EntityName\", StringType(), True),\n",
    "    StructField(\"Operation\", StringType(), True),\n",
    "    StructField(\"Status\", StringType(), True),\n",
    "    StructField(\"BronzeCount\", LongType(), True),\n",
    "    StructField(\"SilverCount\", LongType(), True),\n",
    "    StructField(\"GoldCount\", LongType(), True),\n",
    "    StructField(\"ErrorMessage\", StringType(), True)\n",
    "])\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "def log_append(results_log,stage,table_name,operation,status,\n",
    "                                bronze_count=None,silver_count=None,gold_count=None,error_message=None):\n",
    "    # \n",
    "    # Appends a log entry to the results_log list.\n",
    "    # \n",
    "    results_log.append({\n",
    "        \"LogDate\": datetime.now().date(),\n",
    "        \"ExecutionDate\": datetime.now(),\n",
    "        \"Stage\": stage,\n",
    "        \"EntityName\": table_name,\n",
    "        \"Operation\": operation,\n",
    "        \"Status\": status,\n",
    "        \"BronzeCount\": bronze_count,\n",
    "        \"SilverCount\": silver_count,\n",
    "        \"GoldCount\": silver_count,\n",
    "        \"ErrorMessage\": error_message\n",
    "                })\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "def log_write(spark, results_log, log_table=\"ceo_brz_dev.dbo.entity_log\"):\n",
    "    # \n",
    "    # Writes a log entry to the table\n",
    "    # \n",
    "    if results_log:\n",
    "        results_df = spark.createDataFrame(results_log,schema=log_schema)\n",
    "        results_df.write.format(\"delta\").mode(\"append\").saveAsTable(log_table)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "sql",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "logging_helper.py",
   "widgets": {}
  },
  "language_info": {
   "name": "sql"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
